# docker-compose.yml - Complete production deployment configuration
# Crypto Hunter with comprehensive forensics capabilities

version: '3.8'

# Shared environment variables
x-common-env: &common-env
  SECRET_KEY: ${SECRET_KEY}
  DATABASE_URL: postgresql://crypto_hunter:${DB_PASSWORD}@db:5432/crypto_hunter
  REDIS_URL: redis://redis:6379/0
  CELERY_BROKER_URL: redis://redis:6379/2
  CELERY_RESULT_BACKEND: redis://redis:6379/3
  OPENAI_API_KEY: ${OPENAI_API_KEY:-}
  ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
  SENTRY_DSN: ${SENTRY_DSN:-}
  FLASK_ENV: ${FLASK_ENV:-production}
  LOG_LEVEL: ${LOG_LEVEL:-INFO}
  ENABLE_REGISTRATION: ${ENABLE_REGISTRATION:-false}
  ENABLE_AI_ANALYSIS: ${ENABLE_AI_ANALYSIS:-true}
  ENABLE_BACKGROUND_TASKS: true
  MAX_CONTENT_LENGTH: 1073741824  # 1GB
  FORENSICS_TOOLS_PATH: /opt/forensics-tools
  WORDLISTS_PATH: /opt/wordlists

services:
  # Web Application with comprehensive forensics
  web:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: crypto-hunter-web
    restart: unless-stopped
    ports:
      - "${WEB_PORT:-8000}:8000"
    environment:
      <<: *common-env
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
      - ./instance:/app/instance
      - forensics_data:/opt/forensics-tools
      - wordlists_data:/opt/wordlists
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - crypto-hunter-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.crypto-hunter.rule=Host(`${DOMAIN:-localhost}`)"
      - "traefik.http.services.crypto-hunter.loadbalancer.server.port=8000"

  # Background Worker with forensics tools
  worker:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: crypto-hunter-worker
    restart: unless-stopped
    command: >
      celery -A crypto_hunter_web.services.background_service worker
      --loglevel=info
      --concurrency=4
      --pool=threads
      --queues=forensics_heavy,steganography,binary_analysis,crypto_analysis,ai_analysis
    environment:
      <<: *common-env
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
      - forensics_data:/opt/forensics-tools
      - wordlists_data:/opt/wordlists
      - /tmp:/tmp  # For forensics tool temp files
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - crypto-hunter-network
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '1.0'
          memory: 2G
    healthcheck:
      test: ["CMD", "celery", "-A", "crypto_hunter_web.services.background_service", "inspect", "ping"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 120s

  # Celery Beat Scheduler
  beat:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: crypto-hunter-beat
    restart: unless-stopped
    command: >
      celery -A crypto_hunter_web.services.background_service beat
      --loglevel=info
      --schedule=/tmp/celerybeat-schedule
    environment:
      <<: *common-env
    volumes:
      - ./logs:/app/logs
      - beat_schedule:/tmp
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - crypto-hunter-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M

  # Celery Flower (Task Monitor)
  flower:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: crypto-hunter-flower
    restart: unless-stopped
    command: >
      celery -A crypto_hunter_web.services.background_service flower
      --port=5555
      --basic_auth=${FLOWER_USER:-admin}:${FLOWER_PASSWORD:-admin}
    ports:
      - "${FLOWER_PORT:-5555}:5555"
    environment:
      <<: *common-env
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - crypto-hunter-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # PostgreSQL Database
  db:
    image: postgres:15-alpine
    container_name: crypto-hunter-db
    restart: unless-stopped
    environment:
      POSTGRES_DB: crypto_hunter
      POSTGRES_USER: crypto_hunter
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_INITDB_ARGS: --encoding=UTF-8 --lc-collate=C --lc-ctype=C
      POSTGRES_SHARED_PRELOAD_LIBRARIES: pg_stat_statements
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql:ro
    ports:
      - "${DB_PORT:-5432}:5432"
    networks:
      - crypto-hunter-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U crypto_hunter -d crypto_hunter"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G
    command: >
      postgres
      -c shared_preload_libraries=pg_stat_statements
      -c pg_stat_statements.track=all
      -c max_connections=200
      -c shared_buffers=1GB
      -c effective_cache_size=3GB
      -c maintenance_work_mem=256MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200

  # Redis Cache and Message Broker
  redis:
    image: redis:7-alpine
    container_name: crypto-hunter-redis
    restart: unless-stopped
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
      - ./config/redis.conf:/etc/redis/redis.conf:ro
    networks:
      - crypto-hunter-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.2'
          memory: 256M
    command: >
      redis-server /etc/redis/redis.conf
      --appendonly yes
      --maxmemory 1gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000

  # NGINX Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: crypto-hunter-nginx
    restart: unless-stopped
    ports:
      - "${HTTP_PORT:-80}:80"
      - "${HTTPS_PORT:-443}:443"
    volumes:
      - ./config/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./config/nginx/crypto-hunter.conf:/etc/nginx/conf.d/default.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
      - ./static:/var/www/static:ro
    depends_on:
      - web
      - flower
    networks:
      - crypto-hunter-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  # Forensics Tools Container (for complex analysis)
  forensics-tools:
    build:
      context: ./docker/forensics
      dockerfile: Dockerfile
    container_name: crypto-hunter-forensics
    restart: "no"  # Only run when needed
    volumes:
      - ./uploads:/data:ro
      - forensics_output:/output
      - forensics_data:/opt/forensics-tools
      - wordlists_data:/opt/wordlists
    networks:
      - crypto-hunter-network
    profiles:
      - forensics
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G

  # Prometheus Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: crypto-hunter-prometheus
    restart: unless-stopped
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=90d'
      - '--web.enable-lifecycle'
    networks:
      - crypto-hunter-network
    profiles:
      - monitoring

  # Grafana Dashboard
  grafana:
    image: grafana/grafana:latest
    container_name: crypto-hunter-grafana
    restart: unless-stopped
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_USERS_ALLOW_SIGN_UP: false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./config/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
    networks:
      - crypto-hunter-network
    profiles:
      - monitoring

  # Elasticsearch (for log analysis)
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: crypto-hunter-elasticsearch
    restart: unless-stopped
    environment:
      discovery.type: single-node
      ES_JAVA_OPTS: -Xms1g -Xmx1g
      xpack.security.enabled: false
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "${ELASTICSEARCH_PORT:-9200}:9200"
    networks:
      - crypto-hunter-network
    profiles:
      - logging
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G

  # Kibana (for log visualization)
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: crypto-hunter-kibana
    restart: unless-stopped
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    ports:
      - "${KIBANA_PORT:-5601}:5601"
    depends_on:
      - elasticsearch
    networks:
      - crypto-hunter-network
    profiles:
      - logging

  # Backup Service
  backup:
    image: alpine:latest
    container_name: crypto-hunter-backup
    restart: "no"
    volumes:
      - postgres_data:/backup/postgres:ro
      - redis_data:/backup/redis:ro
      - ./uploads:/backup/uploads:ro
      - ./backups:/backups
      - ./scripts/backup.sh:/backup.sh:ro
    command: /backup.sh
    depends_on:
      - db
      - redis
    networks:
      - crypto-hunter-network
    profiles:
      - backup

# Networks
networks:
  crypto-hunter-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# Persistent volumes
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  elasticsearch_data:
    driver: local
  forensics_data:
    driver: local
  forensics_output:
    driver: local
  wordlists_data:
    driver: local
  beat_schedule:
    driver: local

---
# docker-compose.override.yml - Development overrides
version: '3.8'

services:
  web:
    build:
      target: development
    environment:
      FLASK_ENV: development
      DEBUG: true
      WTF_CSRF_ENABLED: false
      LOG_LEVEL: DEBUG
    volumes:
      - .:/app
    command: python run_local.py
    ports:
      - "8000:8000"

  worker:
    build:
      target: development
    environment:
      FLASK_ENV: development
      LOG_LEVEL: DEBUG
    volumes:
      - .:/app
    command: >
      celery -A crypto_hunter_web.services.background_service worker
      --loglevel=debug
      --concurrency=2
      --pool=solo

  beat:
    build:
      target: development
    environment:
      FLASK_ENV: development
      LOG_LEVEL: DEBUG
    volumes:
      - .:/app

  flower:
    build:
      target: development
    volumes:
      - .:/app

  # Development database with different credentials
  db:
    environment:
      POSTGRES_DB: crypto_hunter_dev
      POSTGRES_USER: crypto_hunter
      POSTGRES_PASSWORD: dev_password
    ports:
      - "5432:5432"

  # Development redis
  redis:
    ports:
      - "6379:6379"

---
# docker-compose.test.yml - Testing configuration
version: '3.8'

services:
  test:
    build:
      context: .
      target: development
    environment:
      FLASK_ENV: testing
      DATABASE_URL: sqlite:///test.db
      CELERY_TASK_ALWAYS_EAGER: true
      CELERY_TASK_EAGER_PROPAGATES: true
    volumes:
      - .:/app
    command: python -m pytest tests/ -v --cov=crypto_hunter_web
    networks:
      - crypto-hunter-network

  test-db:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: crypto_hunter_test
      POSTGRES_USER: test
      POSTGRES_PASSWORD: test
    tmpfs:
      - /var/lib/postgresql/data
    networks:
      - crypto-hunter-network

---
# docker-compose.prod.yml - Production overrides
version: '3.8'

services:
  web:
    build:
      target: production
    environment:
      FLASK_ENV: production
    deploy:
      replicas: 3
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s

  worker:
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3

  # Production nginx with SSL
  nginx:
    volumes:
      - ./config/nginx/prod.conf:/etc/nginx/conf.d/default.conf:ro
      - /etc/letsencrypt:/etc/letsencrypt:ro

  # Enable monitoring in production
  prometheus:
    profiles: []

  grafana:
    profiles: []